{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e976bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "from neural import *\n",
    "from dataset import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data plus some additional preprocessing\n",
    "input_features = []\n",
    "output_labels = []\n",
    "with open(f\"playerData_features.txt\", mode=\"r\",encoding=\"utf-8\") as file:\n",
    "    num_no_prenhl_seasons = 0\n",
    "    for line in file:\n",
    "        player_data = json.loads(line.strip())\n",
    "\n",
    "        player_input_features = []\n",
    "        player_output_labels = []\n",
    "\n",
    "        # multihot encode position\n",
    "        position_mapping = {\"C\": [0], \"LW\": [1], \"RW\": [2], \"D\": [3], \"W\": [1,2], \"F\": [0,1,2]}\n",
    "        positions = [0] * 4\n",
    "        for pos in player_data.get(\"detailedPosition\"):\n",
    "            for i in position_mapping[pos]:\n",
    "                    positions[i] = 1\n",
    "        player_input_features.extend(positions)\n",
    "\n",
    "        left_right_mapping = {\"L\": 0, \"R\": 1, \"N\": 0.5}  # N for neither or unknown\n",
    "        player_input_features.append(left_right_mapping[player_data.get(\"shoots\") if player_data.get(\"shoots\") else \"N\"])\n",
    "\n",
    "        # if player_data.get(\"height\"):\n",
    "        #     player_input_features.append(player_data.get(\"height\"))\n",
    "        # else:\n",
    "        #     continue\n",
    "        # if player_data.get(\"weight\"):\n",
    "        #     player_input_features.append(player_data.get(\"weight\"))\n",
    "        # else:\n",
    "        #     continue\n",
    "\n",
    "        nhl_seasons = torch.zeros(6, dtype=torch.float32)\n",
    "        num_nhl_seasons = 0\n",
    "        nonnhl_seasons = torch.zeros(6, dtype=torch.float32)\n",
    "        num_nonnhl_seasons = 0\n",
    "        # average stats for nhl seasons and non nhl seasons\n",
    "        for season in player_data.get(\"seasonStats\", []):\n",
    "            # maybe could add year later\n",
    "            # could use normal plus minus instead of per game\n",
    "            season_data = torch.tensor([season.get(\"gamesPlayed_log\"), season.get(\"goalsPerGame\"), season.get(\"assistsPerGame\"), season.get(\"pointsPerGame\"), season.get(\"penaltyMinsPerGame\"), season.get(\"plusMinusPerGame\")], dtype=torch.float32)\n",
    "            if season.get(\"league\", \"\") == \"NHL\":\n",
    "                nhl_seasons += season_data\n",
    "                num_nhl_seasons += 1\n",
    "            else:\n",
    "                nonnhl_seasons += season_data\n",
    "                num_nonnhl_seasons += 1\n",
    "\n",
    "        if num_nonnhl_seasons == 0:\n",
    "            num_no_prenhl_seasons += 1\n",
    "            continue\n",
    "        numSamples +=1\n",
    "        # average stats over all seasons\n",
    "        nhl_seasons /= num_nhl_seasons if num_nhl_seasons > 0 else 1\n",
    "        nonnhl_seasons /= num_nonnhl_seasons if num_nonnhl_seasons > 0 else 1\n",
    "\n",
    "        player_input_features.extend(nhl_seasons.tolist())\n",
    "        player_output_labels.extend(nonnhl_seasons.tolist())\n",
    "\n",
    "        input_features.append(player_input_features)\n",
    "        output_labels.append(player_output_labels)\n",
    "\n",
    "print(f\"number of players with no non NHL seasons: {num_no_prenhl_seasons}\")\n",
    "print(f\"number of samples: {len(input_features)}\")\n",
    "\n",
    "print(\"numInputFeatures:\", len(input_features[0]))\n",
    "print(\"numOutputLabels:\", len(output_labels[0]))\n",
    "\n",
    "\n",
    "train_dataset = NHLDataset(input_features[:-800], output_labels[:-800])\n",
    "validation_dataset = NHLDataset(input_features[-800:-400], output_labels[-800:-400])\n",
    "test_dataset = NHLDataset(input_features[-400:], output_labels[-400:])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458caec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "# TODO change model shape\n",
    "model = MLP(input_size=11, output_size=6, hidden_size=30, num_hidden_layers=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)\n",
    "print(f\"number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "train_losses, validation_losses = [], [] \n",
    "cur_epoch = 0\n",
    "\n",
    "def trainModel(model: nn.Module, dataloader: torch.utils.data.DataLoader, criterion: nn.Module, optimizer: torch.optim.Optimizer, device: torch.device) -> float:\n",
    "    # trains the model for one epoch\n",
    "    # return average loss over epoch\n",
    "    model.train()\n",
    "    totalLoss = 0\n",
    "    n = len(dataloader)\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        totalLoss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return totalLoss/n\n",
    "\n",
    "def evaluateModel(model: nn.Module, dataloader: torch.utils.data.DataLoader, criterion: nn.Module, device: torch.device,) -> float:\n",
    "    # evaluates the model\n",
    "    # return average loss\n",
    "    model.eval()\n",
    "    totalLoss = 0\n",
    "    n = len(dataloader)\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        totalLoss += loss.item()\n",
    "    return totalLoss/n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add ability to save model\n",
    "\n",
    "num_epochs = 100\n",
    "for _ in range(num_epochs):\n",
    "    train_loss = trainModel(model, train_loader, criterion, optimizer, device)\n",
    "    validation_loss = evaluateModel(model, validation_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    validation_losses.append(validation_loss)\n",
    "\n",
    "    cur_epoch += 1\n",
    "\n",
    "    print(f\"Epoch {cur_epoch}| Train Loss: {train_loss:.4f}| Validation Loss: {validation_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and validation loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.title(f\"Training and Validation Loss\")\n",
    "plt.plot(train_losses, label=f\"Train\")\n",
    "plt.plot(validation_losses, label=f\"Validationn\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def print_metrics(model, dataloader, device):\n",
    "    model.eval()\n",
    "    allPreds, trueOutputs = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x)\n",
    "            allPreds.extend(preds.cpu().numpy())\n",
    "            trueOutputs.extend(y.cpu().numpy())\n",
    "\n",
    "        print(mean_squared_error(trueOutputs, allPreds))\n",
    "        print(root_mean_squared_error(trueOutputs, allPreds))\n",
    "        print(mean_absolute_error(trueOutputs, allPreds))\n",
    "        print(r2_score(trueOutputs, allPreds))\n",
    "\n",
    "\n",
    "print(f\"\\nMetrics - Testing\\n\")\n",
    "print_metrics(model, test_loader, device)\n",
    "print(f\"\\nMetrics - Validation\\n\")\n",
    "print_metrics(model, validation_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f128db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model - when training complete\n",
    "test_loss = evaluateModel(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Final Train Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {validation_losses[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
